# AI Is Biased. Here's How Scientists Are Trying to Fix It

> Researchers are revising the ImageNet data set. But algorithmic anti-bias
> training is harder than it seems.

An AI algorithm called ImageNet was made that could identify images based on
labels that humans gave them. However this resulted in some things being
identified as slurs or other offensive phrases.

Although the algorithm is technically exact, the human bias and stereotypes
found its way into the dataset, meaning the algorithm's objectivity was
compromised.

Scientists countered this by creating other machines that could identify human
prejudice and remove it from the data set. This is still imperfect, as it is
still a human-made algorithm, but it is better than nothing.

They look for terms that project meaning, like "philanthropist", and try to
remove those. This (in theory) results in only objective, fair terms being left
behind.

> "Debiasing humans is harder than debiasing AI systems" - Olga Russakovsky,
> Princeton
